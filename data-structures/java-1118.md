# searches

## linear searching
big o of n
- makes on assumption about data being in order, therefore slower

## binary searching
- take large data set and divide in half again and again, until find what looking for
- requires sorted data
- need low/high/mid/data(info looking for)
    - either get to location where 1 piece of data, if it's the piece you want, return iindex
- simlar to recursion
- has something similar base case, like recursion
- number of comparisons is equal to 2^n = y where y is >= array size.
    - eg if array.length = 100,000 total comparisons = 17 checks
- 4 billion == 32 searches
eg:
```
public int binarySearch(int array[], int data) {
    int lo = 0;
    int hi = array.length -1;
    boolean found = false;
    while( low <= hi){
        int mid = (low + hi) / 2; // first round mid == 49;
        if (array[mid] == data){
            return mid
        }
        if (data > array[mid]){
            lo = mid++;
        } else {
            hi = mid -1;
        }
    }
    return -1;
}
```

- recursion:
int idx = recBinSearch(array, data, 0, array.length-1)

```
recBinSearch (int array[] int data int lo, int hi){
    if (lo > hi) { // base case
        return -1;
    }
    int mid = (lo + hi) /2
    if (array[mid]) == data{
        return mid;
    }
    if (array[mid]) < data{
        return recBinSearch(array, data, mid + 1, hi)
    }
    return recBinSearch(array, data, mid + 1, hi)

}

```

## Hash function
big O 1 better than big O n
- approaching big O 1
- works on data, calculates location where data should live inside an array
- idx = data % array.length;
    - 
`collision` - 2 pieces of data want to live in same `bucket`
`bucket` - each place in array
`collision resolution` - resolving collision for bucket
- on collision, probe for new location
- `linear probing` - if collision, but data in next place 
    - added linear component to something that was big O 1
    - not a very good idea, especially if have lots of data falling into location that hash function tells it to go to
    - on `meta scale`, will see `clustering` of data
- `clustering` is sign of inefficiency
    - means required `probing`
- perfect hash table is big O 1
- if collision, can rehash data
`hash vs probe`
- probe based on location in table
- hashing is based on data
- resolve collision with probing
- initial foray into table, use hashing
- many probings: `quadratic probing`, `linear probing`
    - quadratic probing - if collision, try 1^2, 2^2, 3^2 buckets away from initial collision
`open address`
- has hashing and probing
- fill never used buckets with `never used`
- fill emptied used buckets with `previously used`
- if deleting
- review find process, does linear probing where get id and if doesn't match then go to next bucket, and next and next, if reacy `never used`, know doesn't exist

# chained hashing
- array of linked lists
- linked list will be linear
- can be queue or stack