# Load balancer
- extension of NodePort type of service
- redirects traffic to all nodes and nodePorts
- clients only talk to load balancers IP address
- not "pod aware"
    - if 2 pods on node A and 1 pod on node B, won't distribute evenly between pods
        - because LB isn't aware of pods/containers inside node
    - solution: use ip-tables to figure out where pod is in cluster and will route there, regardless of what node it is on
        - then k8s sends to originating node, to send to ip-tables and properly route out
            - this creates latency
            - can reduce latency by setting annotation to always pick the pod on that node. Won't properly load balance, but will fix latency.
            - `kubectl describe services <name>` - see no annotations listed
            - `kubectl annotate service <name> externalTrafficPolicy=Local`


- no service interuption if a node goes down
    - can split traffic

## LoadBalancer service
- if cluster is on cloud infrastructure, can create LoadBalancer service
- yaml Spec will not specify NodePort - because k8s will choose for you
- `sessionAffinity` - balancing between nodes. If "none" will balance evenly

- `kubectl get services`
    - if <none>, service is only accessible internally
        - service can only talk to one node at a time


# Ingress

- like a load balancer, but can access multiple services with a single external IP address
    - load balancer has 1 external IP address for every service
- exposes http/https routes from outside the cluster, to services inside the cluster
- operates at application layer
- provides features that Services cannot
- ingress controller and ingress resource are created

## Ingress resource

## Ingress controller